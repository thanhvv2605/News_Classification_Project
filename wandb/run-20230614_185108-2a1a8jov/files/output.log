36/36 [==============================] - 0s 2ms/step
For each class:
Accuracy:  tensor([0.7541, 0.6059, 0.7792, 0.7781, 0.6622, 0.6817, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000])
Precision:  tensor([0.7773, 0.6428, 0.8646, 0.8203, 0.6440, 0.5557, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000])
Recall:  tensor([0.7541, 0.6059, 0.7792, 0.7781, 0.6622, 0.6817, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000])
F1-score:  tensor([0.7655, 0.6238, 0.8197, 0.7986, 0.6530, 0.6123, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000])
Type:  micro
Accuracy:  tensor(0.7100)
Precision:  tensor(0.7100)
Recall:  tensor(0.7100)
F1-score:  tensor(0.7100)
Type:  macro
Accuracy:  tensor(0.1065)
Precision:  tensor(0.1076)
Recall:  tensor(0.1065)
F1-score:  tensor(0.1068)
Type:  weighted
Accuracy:  tensor(0.7100)
Precision:  tensor(0.7191)
Recall:  tensor(0.7100)
F1-score:  tensor(0.7129)
THe length of the datset after dublicate deletion------> (209038, 6)
THe length of the datset ------> (209036, 6)
the lenth of the blank description samples-----> 19610
THe length of the datset ----------------------> (189426, 6)
the lenth of the blank auhtor samples----------> 32853
THe length of the datset ----------------------> (156573, 6)
THe length of the datset after dublicate deletion------> (209038, 6)
THe length of the datset ------> (209036, 6)
the lenth of the blank description samples-----> 19610
THe length of the datset ----------------------> (189426, 6)
the lenth of the blank auhtor samples----------> 32853
THe length of the datset ----------------------> (156573, 6)
The X_train shape-----> (25312, 30)
The X_text shape------> (11250, 30)
THe y_train shape-----> (25312, 15)
The y_test shape------> (11250, 15)
Epoch 1/20
198/198 [==============================] - 3s 12ms/step - loss: 2.9370 - categorical_accuracy: 0.1836 - val_loss: 2.5594 - val_categorical_accuracy: 0.1413
Epoch 2/20
198/198 [==============================] - 2s 10ms/step - loss: 2.4123 - categorical_accuracy: 0.1711 - val_loss: 2.3440 - val_categorical_accuracy: 0.2050
Epoch 3/20
198/198 [==============================] - 2s 11ms/step - loss: 2.1857 - categorical_accuracy: 0.2610 - val_loss: 2.1968 - val_categorical_accuracy: 0.2783
Epoch 4/20
198/198 [==============================] - 2s 12ms/step - loss: 1.9480 - categorical_accuracy: 0.3763 - val_loss: 2.1732 - val_categorical_accuracy: 0.3192
Epoch 5/20

198/198 [==============================] - 3s 16ms/step - loss: 1.7498 - categorical_accuracy: 0.4693 - val_loss: 2.2497 - val_categorical_accuracy: 0.3357
Epoch 6/20

198/198 [==============================] - 4s 22ms/step - loss: 1.5542 - categorical_accuracy: 0.5645 - val_loss: 2.4122 - val_categorical_accuracy: 0.3411
Epoch 7/20

198/198 [==============================] - 4s 21ms/step - loss: 1.3617 - categorical_accuracy: 0.6694 - val_loss: 2.6614 - val_categorical_accuracy: 0.3316
Epoch 8/20

198/198 [==============================] - 4s 20ms/step - loss: 1.1881 - categorical_accuracy: 0.7592 - val_loss: 2.9619 - val_categorical_accuracy: 0.3269
Epoch 9/20

198/198 [==============================] - 4s 21ms/step - loss: 1.0294 - categorical_accuracy: 0.8419 - val_loss: 3.2486 - val_categorical_accuracy: 0.3252
Epoch 10/20

198/198 [==============================] - 4s 21ms/step - loss: 0.8948 - categorical_accuracy: 0.8995 - val_loss: 3.5129 - val_categorical_accuracy: 0.3189
Epoch 11/20

198/198 [==============================] - 4s 22ms/step - loss: 0.7778 - categorical_accuracy: 0.9407 - val_loss: 3.7427 - val_categorical_accuracy: 0.3169
Epoch 12/20

198/198 [==============================] - 4s 21ms/step - loss: 0.6823 - categorical_accuracy: 0.9666 - val_loss: 3.9494 - val_categorical_accuracy: 0.3162
Epoch 13/20

198/198 [==============================] - 4s 22ms/step - loss: 0.6035 - categorical_accuracy: 0.9801 - val_loss: 4.0652 - val_categorical_accuracy: 0.3103
Epoch 14/20

198/198 [==============================] - 4s 21ms/step - loss: 0.5434 - categorical_accuracy: 0.9884 - val_loss: 4.2358 - val_categorical_accuracy: 0.3091
Epoch 15/20

198/198 [==============================] - 4s 21ms/step - loss: 0.4961 - categorical_accuracy: 0.9935 - val_loss: 4.2598 - val_categorical_accuracy: 0.3088
Epoch 16/20

198/198 [==============================] - 4s 20ms/step - loss: 0.4569 - categorical_accuracy: 0.9959 - val_loss: 4.3485 - val_categorical_accuracy: 0.3073
Epoch 17/20


198/198 [==============================] - 4s 22ms/step - loss: 0.4252 - categorical_accuracy: 0.9970 - val_loss: 4.4625 - val_categorical_accuracy: 0.3098
Epoch 18/20

198/198 [==============================] - 4s 22ms/step - loss: 0.3982 - categorical_accuracy: 0.9979 - val_loss: 4.4967 - val_categorical_accuracy: 0.3059
Epoch 19/20

198/198 [==============================] - 4s 22ms/step - loss: 0.3735 - categorical_accuracy: 0.9983 - val_loss: 4.5681 - val_categorical_accuracy: 0.3047
Epoch 20/20


198/198 [==============================] - 4s 21ms/step - loss: 0.3527 - categorical_accuracy: 0.9986 - val_loss: 4.6210 - val_categorical_accuracy: 0.3075